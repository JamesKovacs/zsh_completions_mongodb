#compdef mongoimport

mode_values=( insert upsert merge delete )
parsegrace_values=( autoCast skipField skipRow stop )
type_values=( json csv tsv )
verbose_values=( 1 2 3 4 5 )

_arguments -S \
  "--help[Show this usage information]" \
  "--version[Show version information]" \
  "--verbose=[More detailed log output (specify a numeric value from 1 to 5)]:arg:_values 'verbose' $verbose_values" \
  "--quiet[Hide all log output]" \
  {-h,--host}"[Server to connect to]:arg:(localhost)" \
  "--port=[Port to connect to]:arg:(27017)" \
  "--ssl[Use SSL for all connections]" \
  "--sslCAFile=[Certificate authority file for SSL]:filename:_files" \
  "--sslPEMKeyFile=[PEM certificate/key file for SSl]:filename:_files" \
  "--sslPEMKeyPassword=[Password for key in PEM file for SSL]:arg:" \
  "--sslCRLFile=[Certificate revocation list file for SSL]:filename:_files" \
  "--sslAllowInvalidHostnames[Allow connections to servers with non-matching hostnames]" \
  "--sslAllowInvalidCertificates[Allow connections to servers with invalid certificates]" \
  "--sslFIPSMode[Activate FIPS 140-2 mode at startup]" \
  {-u,--username}"[Username for authentication]:arg:" \
  {-p,--password}"[Password for authentication]:arg:" \
  "--authenticationDatabase=[User source (defaults to dbname)]:arg:(admin)" \
  "--authenticationMechanism=[Authentication mechanism]:arg:(SCRAM-SHA-256)" \
  "--awsSessionToken=[Session token to authenticate via AWS IAM]:arg:" \
  "--gssapiServiceName=[Service name to use when authenticating using GSSAPI/Kerberos]:arg:" \
  "--gssapiHostName=[Remote host name to use for purpose of GSSAPI/Kerberos authentication]:arg:" \
  "--uri=[MongoDB URI connection string]:arg:" \
  {-d,--db}"[Database to use]:arg:" \
  {-c,--collection}"[Collection to use]:arg:" \
  {-f,--fields}"[Comma separated list of fields e.g. -f \"name,age\"]:arg:" \
  "--fieldFile=[File with field names - 1 per line]:filename:_files:" \
  "--file=[File to import from; if not specified, stdin is used]:filename:_files:" \
  "--headerline[Use first line in input source as the field list (CSV and TSV only)]" \
  "--jsonArray[Treat input source as a JSON array]" \
  "--legacy[Indicates that the import data is in Extended JSON v1 format instead of the default Extended JSON v2 format]" \
  "--parseGrace=[Controls behavior when type coercion fails. One of: autoCast, skipField, skipRow, stop (default: stop)]:arg:_values 'parsegrace' $parsegrace_values" \
  "--type=[Input format to import: json, csv, or tsv (default: json)]:arg:_values 'type' $type_values" \
  "--columnsHaveTypes[Indicate that the field list (from --fields, --fieldsFile, or --headerline) specifies types.]" \
  "--drop[Drop collection before inserting documents]" \
  "--ignoreBlanks[Ignore fields with empty values in CSV and TSV]" \
  "--maintainInsertionOrder[Insert documents in the order of their appearance in the input source]" \
  {-j,--numInsertionWorkers}"[Number of insert operations to run concurrently (default: 1)]:arg:(1)" \
  "--stopOnError[Stop importing at first insert/upsert error]" \
  "--mode=[insert, upsert, merge, or delete. (default: insert)]:arg:_values 'mode' $mode_values" \
  "--upsertFields=[Comma-separated fields for the query part when --mode is set to upsert or merge]:arg:" \
  "--writeConcern=[Write concern options e.g. --writeConcern '{w: 3, wtimeout: 500, fsync: true, j: true}' (default: majority)]:arg:" \
  "--bypassDocumentValidation[Bypass document validation]" \
  "--useArrayIndexFields[Indicates that field names may include array indexes that should be used to construct arrays during import]" \
  && return 0

return 1